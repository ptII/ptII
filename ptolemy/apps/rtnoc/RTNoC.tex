\documentclass[10pt]{article}
\usepackage[english,french]{babel}
\usepackage{graphicx}

\pdfpagewidth 8.5in
\pdfpageheight 11in 

\setlength\topmargin{0in}
\setlength\headheight{0in}
\setlength\headsep{0in}
\setlength\textheight{7.7in}
\setlength\textwidth{6.5in}
\setlength\oddsidemargin{0in}
\setlength\evensidemargin{0in}
\setlength\parindent{0.1in}
\setlength\parskip{0.1in} 

\begin{document}
\begin{center}
\huge{Real-time Communication for Network on Chip} \hspace{0.5cm}
\end{center}
\section{Introduction}
As a network on chip gets larger, the communication on the network becomes 
very complicated. Congestions on that network can occur resulting in unpredictable 
delay in communications between network nodes. This non-deterministic behavior 
makes it very difficult to verify the timing semantics of a network on chip 
system, as a result, network on chip systems become unsuitable for real-time 
applications, especially critical control applications.

\begin{figure}[htp]\label{fig:NoCRt}
\centering
\includegraphics[width=7cm]{pics/NoC0}
\caption[Demand for a hard real-time flow.]
{How can a sending node make sure about the bounded delay for
a packet?}
\end{figure}

Our purpose is to bring the real-time communication to network on chip so that 
users can always guarantee deterministic behaviors of a critical system. To do 
so, it requires bounded delay communications between nodes in the network. 
For example, when processing element $0$ wants to send a critical control packet 
p to processing element $11$, how can it know for sure that the packet will
reach the destination within a certain amount of time? 

\section{Related Work}
\subsection{\AE thereal}
This work \cite{Goossens_chapter4} is from NXP. This architecture tries to avoid
contention using contention-free routing by {\em delaying} some packets. 

Guaranteed packets are multiplexed using TDMA. However, this approach requires
design-time configuration and verification, which is not flexible for architectures
like multicore.
\subsection{SoCBUS}
SoCBUS architecture \cite{SoCBUS} is from Linkoping University. It seeks to 
guarantee real-time properties by setting up a path before ending:
\begin{itemize}
\item Init a path by sending a setting up packet.
\item The path will be {\em blocked} until all data have been sent.
\item After that the path is unlocked
\end{itemize}
This approach has the following problems: 
\begin{itemize}
\item What happens if we have two real-time paths on the same link?
\item Other traffic sharing a link with this real-time path is blocked while 
data is sent. This seems to be a good solution when sending a large bulk of data 
but not good for periodic, un-continuous flows.
\item Utilization of this approach can be low if real-time flows only require
low bandwidth.
\end{itemize}
\subsection{QNoC}
This work is from Technion \cite{QNoC}. Packets are sent synchronously. 
This architecture supports multi service levels as in table \ref{table:QNoCTable}.

\begin{table}[h]
\begin{center}
  \begin{tabular}{ | p{2.5cm} | p{6cm} | p{2cm} |}
    \hline
	Service-Level & Description & Priority \\ \hline
	Signaling & Urgent Messages, Short Packets, Interrupts, Control signals 
	requiring low transport latency & Highest \\ \hline
	Real-Time & Real-time and streaming packets & \\ \hline
	RD/WR & Short memory and register access & \\ \hline
	Block Transfer & Long messages and blocks of data & Lowest \\
    \hline
  \end{tabular}
\end{center}
\caption{QNoC Service Levels}
\label{table:QNoCTable}
\end{table}

This seems to be a good approach for soft real-time applications like video streaming
but this is not really suited for hard real-time applications since what happens 
when multiple real-time flows have to share the same link:
\begin{itemize}
\item Non-deterministic behaviors for flows.
\item Signaling packets can block real-time packets.
\end{itemize}
To solve this problem, we need to keep track of the number and specifications of
real-time flows on a link to make sure that the link is never overloaded.

\section{Our Idea}
We can achieve the real-time communication betweens some nodes in a network 
on a chip by borrowing the resource reservation idea \cite{Zhang93rsvp} from the 
Internet to the network on chip. In that, all the real-time communications 
have to be previously reserved on the network. 

Real-time flows can be multiplexed \cite{Ferrari90ascheme, Zhang_1service} on links in networks without violating
real-time requirements. Other best-effort flows can still use remaining bandwidth on reserved links.

An admission control mechanism is implemented, thus when a reservation 
for a real-time flow is initiated by a sender in a network, the network will determine if 
it can accept that reservation or not based on its current state of other 
reservations of other real-time flows on the network.

\begin{figure}[htp]\label{fig:FlowMultiplex}
\centering
\includegraphics[width=7cm]{pics/Multiplex2}
\caption[Real time flow multiplexing.]
{Real-time flow multiplexing.}
\end{figure}

We will design an architecture with the following advantages:
\begin{itemize}
\item Multiple real-time flows can be multiplexed on one link
\cite{Ferrari90ascheme} as in Figure \ref{fig:FlowMultiplex}.
\item Utilize the spatial data paths between sources and nodes to avoid the 
conflicts between real-time flows.
\item Does not block links completely as SoCBUS \cite{SoCBUS}, best-effort flows 
still can travel links used by real-time flows.
\item Avoid unpredicted behaviors networks as in QNoC \cite{QNoC}, when there are 
multiple real-time flows suddenly travelling on the same link and their total bandwidth 
exceeds the bandwidth of the link. The admission control in our architecture can 
prevent that. Senders should always know if their required specifications for 
their communications can be met or not. 
\item Provide a reconfigurable state for real-time flows on a network, we do not 
need to pre-calculate that at design time as in \AE thereal \cite{Goossens_chapter4}, 
which is really not suitable for the multi-core architecture.
\end{itemize}
\section{Formal Definitions}
\begin{itemize}
\item $t_f$ is the {\em minimum} packet interval time in cycles between two
secessive packets of a real-time flow $f$.
\item $l_f$ is the {\em maximum} length of a packet in flits of real-time flow
$f$.
\item $s_{f,e}$ is the service time for a packet in a node including header 
processing, transmission time, and any other operations. $s$ is often a 
function of $l$: $s=f(l)$. We can set $s=value(l)$, this means that it takes $1$
cycle for a router to process and send one flit over a link. In pipeline router
model as in \cite{PehDelayModel, PehSpecPipeR}, we have to add some pipeline stages to $l$ to have $s$. 
\item $T \subseteq \mathbf{N}$ is the set of the min interval values between packets of flows. 
\item $L \subseteq \mathbf{N}$ is the set of packet lengths.
\item $D \subseteq \mathbf{N}$ is the set of packet delays of real-time flows.
\item $\mathcal{V} \subseteq \mathbf{N}$ is the set of virtual channels between pairs of nodes.
\item $C$ is the set of {\em cores} on the on-chip network.
\item $R$ is the set of {\em routers}.
\end{itemize}

Then the set of {\em nodes} on the network is defined as:
\begin{equation}\label{reio}
V = C \cup R
\end{equation}
And $E$ defined as:
\begin{equation}
E \subseteq V \times V 
\end{equation}
is the set of {\em directed edges} between nodes in the network.

The set of {\em flows} on the network is defined as:
\begin{equation}
F \subseteq C \times C \times \mathcal{V} 
\end{equation}

And $P$ is a {\em mapping } between a real-time flows with its specifications:
\begin{equation}
P:F \rightarrow \tau \times T \times L \times D
\end{equation}
in which $\tau$ is the set of flit types.

\begin{equation}
y_{f,e} = \left\{ \begin{array}{lrc}
1 \mbox{ if flow } f \in F \mbox{ uses link } e \in E \\
0 \mbox{ otherwise} 
\end{array}\right.
\end{equation}

\begin{equation}
\delta_{f,v} = \left\{ \begin{array}{lrc}
1 \mbox{ if flow } f \in F \mbox{ going through node } v \in V \\
0 \mbox{ otherwise} 
\end{array}\right.
\end{equation}

\begin{equation}
I_{v,e} = \left\{ \begin{array}{lrc}
1 \mbox{ if } e \in E \mbox{ is outgoing edge from } v \in V \\
-1 \mbox{ if } e \in E \mbox{ is incoming edge from } v \in V \\
0 \mbox{ otherwise}
\end{array}\right. 
\end{equation}

$\forall f=(s, d, id) \in F$  let $b$ be a vector s.t. $b_f(s) = 1$, 
$b_f(d) = -1$ and $b_f(i) = 0, \forall i \in C \mbox{ and } i \neq s, d$,
 then we have $Iy_f=b_f$, this condition is for unique path between $s$ and $d$.

Configuration $\mathcal{C}(F)=(P, \{y_f\}_{f \in F})$.
\section{Architecture}
At each node in a router, we employ the Internet stack to each node in the 
network on chip.
\begin{table}[h]
\begin{center}
  \begin{tabular}{ | l | }
    \hline
    Application layer at processing units \\ \hline
    Transport layer at processing units \\ \hline
    Network layer at routers \\ \hline
	Data link layer at routers \\ \hline
	Physical layer \\
    \hline
  \end{tabular}
\end{center}
\caption{Network stack model}
\label{table:NetworkStack}
\end{table}

\subsection{Path Setup Protocol}
When in need of a real-time communication, the processing unit at each node 
will issue a request for setting up a path:

{\em Setuppath.request(source\_id, destination\_id, virtual\_channel\_id T, L,
D);}

\begin{figure}[htp]
\centering
\includegraphics[width=10cm]{pics/Protocol2}
\label{fig:ReqSetup}
\caption[Setup request for a real-time flow.]
{Real-time flow setup protocol.}
\end{figure}

This request will be sent over the network by a REQ message to a specific node
in the network, called {\em master node}, as in Figure \ref{fig:ReqSetup}.
Based on its knowledge about other flows in the network and the demand for the
new real-time flow, the master node will seek to find a suitable path. If there
exists a suitable path, the master node will send SETUP command messages to
appropriate routers in the network to config routers' configurations. This re-configuration
can include adjusting configurations of other flows at the routers.

Routers receiving SETUP command message will adjust their internal
configurations as specified in the message. After finishing setting up internal
configurations, routers will send back an acknowledgement ACK message to
the master node. When the master node have received all its expected ACK
messages from routers, it sends an ACCEPT message to the requesting node
(node requested a new real-time flow). The requesting node can start sending
data after receiving that ACCEPT message.

If the master node cannot find a suitable path, it sends back to the requesting
node a REJECT message saying that new real-time flow cannot be set up on the
network.

So the setting up path response can be: ACCEPT, REJECT

\subsection{Questions}
\begin{itemize}
\item Should we specify the path directly in this request? Static initialization 
can be useful in some programming model like Giotto.	
\item Is it possible that the acceptance message will be blocked on the network 
or it reaches the source too late? We should give priority to such kind of control
message.
\item Real-time flows block other best-effort packets traveling on the link when 
the utilization of all the packets on the link is $1$. We need a mechanism to
reroute all best-effort packets.
\end{itemize}

To reduce the size of each router, we can use processing elements to do 
complicated tasks like calculating admission criteria for a new flow at each node 
and rerouting for finding a new suitable path on a network.


One interesting characteristic of this scheme is that the buffer for each 
real-time flow at each node is bounded \cite{Ferrari90ascheme}, and thus
real-time packets can be sent {\em asynchronously} resulting in better bandwidth
since we do not have to send {\em acknowledgement} for each flit sent. So at
data link layer, we employ heterogeneity communications, {\em synchronous}
communications for best effort packets and {\em asynchronous} communications
for real-time packets.

\section{Theoretical Foundations}
\subsection{Delay Model in Cut-through Networks}

The delay model in \cite{Ferrari90ascheme, VermaJitter91} is
for store-and-forward networks \cite{DallyPrinNetwork} (a packet has to be
received {\em completely} by a router before it can be forwarded). However, we
are considering cut-through networks (a packet can be sent while being
received) since it has better throughput.

{\textbf{Definitions}}

$q_{f,v}$ is the {\em maximum} delay of a {\em flit} in flow $f$ at
hop (router) $v$ in cycles.This is the {\em queueing} delay.

The delay at each node of a packet is defined as the duration from the header
of that  packet is received until the header is started to send, then we do not need to include
the service time of the packet itself at the node. The {\em minimum} local
delay of a packet at a node is thus the same as the maximum delay of a flit
at a node since we do not allow to preempt real-time packets. In
\cite{Ferrari90ascheme}, the delay is :

\begin{equation}\label{equ:nodedelay1}
q_{i,n} = \sum_{j=1}^{i-1}s_{j,n}+s_{max} \forall i = 1, ..., K
\end{equation}

 
$p_{f,e}$ is the propagation delay of a {\em flit} of flow f on link $e
\in E$. In network on chip, $p_e=1 \forall e \in E$.

$r_{v,f,u}$ is the time of flit $u$ of flow $f$ reach node $v$.  

$d_{f,e}$ is the {\em maximum} delay of flow $f$ on link $e$ measured in
cycles. This delay is the period between the time a flit reaches one node:
\begin{equation}\label{equ:edgeDelay}
d_{f,e} = q_{f,v}\delta_{f,v} + p_{e} = q_{f,v}\delta_{f,v} + 1 
\end{equation}

and
\begin{equation} 
d_{f,e}y_{f,e} \geq I_{v,e}y_{f,e}r_{v,f,e} + I_{v',e}y_{f,e}r_{v',f,e}
\end{equation}

From \cite{Ferrari90ascheme}, for a simple case, if we assume that all $K$ 
real-time flows going through a node $n$ satisfy the following condition:
\begin{equation}\label{equ:intervalservice1}
t_i \geq \sum_{j=1}^Ks_{j,n}, \forall i = 1,...,K
\end{equation}
the inequality (\ref{equ:intervalservice1}) can be expressed in the flowing way:
\begin{equation}
t_f y_{f,e}\geq \sum_{f^{'} \in F} s_{f^{'}}y_{f^{'},e}, \forall e \in E
\end{equation}
or
\begin{equation}
P(f)(2) y_{f,e}\geq \sum_{f^{'} \in F} s_{f^{'}}y_{f^{'},e}, \forall e \in E
\end{equation}
This means that no deadlines for subsequent packets of a real-time flow will fall within the interval 
between time $t_0$ and $t_0 + \sum s = t_0 + \sum_{j=1}^Ks_{j,n}$. 

We define a function $order_v(f)$ over the set of all real-time flows $F$
as a function to determine if there are two packets $p1$ and $p2$, arriving at a
node $v$ at the same time of two real-time flows $f1$ and $f2$ respectively
and competing for an output link $e$, packet $p1$ will be sent before $p2$ if
$order_{v,e}(f1) > order_{v,e}(f2)$.

%include scheduling figure here

In our cut-through network, the local delay at each node is a little bit
different from \cite{Ferrari90ascheme} as shown in the below equation:

\begin{equation}\label{equ:queueDelay}
q_{f,v}y_{f,e} = \sum_{g \in F:order_v(g) <
order_v(f)}\delta_{g,v}y_{f,e}s_{f,e} + max(s_{i \in F}y_{i,e})-1, \forall e \in
E
\end{equation}

The local delay has to be subtracted one since the notion of time in
\cite{Ferrari90ascheme} is continuous so that time $0+$ is basically $0$ but in
our network with the notion of time is discrete, the time $0+$ is $1$ cycle
latter.

From (\ref{equ:edgeDelay}) and (\ref{equ:queueDelay}) we then have:

\begin{equation}\label{equ:edgeDelay1}
d_{f,e}y_{f,e} = \sum_{g \in F:order_v(g) <
order_v(f)}y_{f,e}s_{f,e} + max(s_{i \in F}y_{i,e}), \forall e \in
E
\end{equation}

If we set $order_{v,e}(f)=l_f$, the maximum packet length of flow $f$, then
(\ref{equ:edgeDelay1}) becomes:

\begin{equation}\label{equ:edgeDelayPacketLength}
d_{f,e}y_{f,e} = \sum_{g \in F:l_g < l_f}y_{f,e}s_{f,e} +
max(s_{i \in F}y{i,e}), \forall e \in E
\end{equation}

This means that, flows with smaller maximum packet lengths will be given smaller delays
at this node (thereby smaller deadlines when packets come at the same time). This ordering scheme 
will give the smallest {\em overall} delay at this node.

\subsection{Configuration}
A valid configuration $\mathcal{C}(F)$ must satisfy $(\ref{connectivity1}) 
(\ref{equ:e2eDelayST}) (\ref{equ:utilization1})$

\begin{equation}\label{connectivity1} Iy_f=b_f,\forall f \in F
\end{equation}

The total delay at each hop of a real-time flow has to satisfy the delay constraint
of the real-time flow.

\begin{equation}\label{equ:e2eDelayST}
\sum_{e \in E}d_{f,e}y_{f,e} \leq P(f)(4), \forall f \in F
\end{equation}

When multiple real-time flows share the same link, the following conditions
 have to be met on each shared link \cite{Ferrari90ascheme, VermaJitter91}:

\begin{equation}\label{equ:utilization1}
\sum_{f \in F}\frac{s_{f,e}}{P(f)(2)}y_{f,e} \leq 1, \forall e \in E
\end{equation}

Since $S$ is a function of the packet length, for a simple (non-pipeline) router
model, we often have $s=P(f)(3)$, then (\ref{equ:utilization1}) becomes:

\begin{equation}\label{equ:utilization2}
\sum_{f \in F}\frac{P(f)(3)}{P(f)(2)}y_{f,e} \leq 1, \forall e \in E
\end{equation}

At each node, we use Earliest Deadline First (EDF) \cite{VermaJitter91} 
to schedule packets, the deadline for each packet of flow $f$ at node $n^{th}$
is computed as follows: 
\begin{equation}\label{equ:deadline1}
dl_{f,n}=t_0 + \sum_{k=1}^{n}q_{f,k}+P_n
\end{equation}
where $t_0$ is the time the packet is sent from the source and $P_n$ is the propagation
delay from the source till node $n^{th}$ (communication time). We set
$P_n=n$ since in network on chip, it takes one cycle for a head flit to travel
between two successive nodes. Thus, (\ref{equ:deadline1}) becomes:

\begin{equation}\label{equ:deadline2}
dl_f,n=t_0 + \sum_{k=1}^{n}d_{i,k}
\end{equation}

However (\ref{equ:e2eDelayST}) is for a store-forward networks, in a
cut-through network, it becomes
\begin{equation}\label{equ:e2eDelayCT}
\sum_{e \in E}d_{f,e}y_{f,e} + (s_f - 1) \leq P(f)(4), \forall f \in F
\end{equation}
since we have to include the service time, $s_f-1$, for a packet of flow $f$ at
the last node to receive {\em remaning} flits in the packet, not only the
header.

For simple router models (non-pipeline), we have $s_f = P(f)(3)$, then
(\ref{equ:e2eDelayCT}) becomes:
\begin{equation}\label{equ:e2eDelayCTNonPipeline}
\sum_{e \in E}d_{f,e}y_{f,e} + P(f)(3) - 1 \leq P(f)(4), \forall f \in F
\end{equation}

From (\ref{equ:edgeDelayPacketLength}) and (\ref{equ:e2eDelayCTNonPipeline}) we have:
\begin{equation}\label{equ:e2eDelayCTNonPipeline1}
\sum_{e \in E} (\sum_{\forall g \in F:l_g <
l_{f}}y_{g,e}s_{g,e}+max(s_{i \in F}.y_{i,e}))y_{f,e} \leq P(f)(4)-P(f)(3) + 1,
\forall f \in F
\end{equation}

Now a valid configuration $\mathcal{C}(F)$ has to satisfy (\ref{connectivity1}) 
(\ref{equ:utilization2}) (\ref{equ:e2eDelayCTNonPipeline1})

\subsection{Dynamic Path Establishment and Routing}
When a new real-time path needs to be set up with some specifications, we have:
$F \rightarrow F \cup \{f^{'} \}=F^{'}$
and $T \rightarrow T^{'}$ s.t. $T^{'} (f)=T(f)\forall f \in F$ and $T^{'} (f^{'} )=(\tau ^{'}, T^{'}, L^{'}, D^{'})$.

The problem becomes: Find $y_{f^{'}e}$ s.t. $\mathcal{C}(F^{'})$ is valid
when we know that $\mathcal{C}(F)$ is valid.

For a new configuration $\mathcal{C}(F^{'})$, we find a new flow $f^{'}$ such that
the conditions (\ref{connectivity1})(\ref{equ:utilization2}) are satisfied. And
the path delay constraint from (\ref{equ:e2eDelayCTNonPipeline}) is:
\begin{equation}\label{equ:e2eDelayNewPath}
\sum_{e \in E} (\sum_{\forall g \in F:l_g <
l_{f'}}y_{g,e}s_{g,e}+max(s_{i \in F}.y_{i,e}))y_{f',e} \leq P(f')(4)-P(f')(3) +
1, f' \in F
\end{equation}

If we assume the maximum service time for one packet at a node of a flow is the same
for all nodes and again the router model is simple (non-pipeline) then we have:
\begin{equation}\label{equ:e2eDelayNewPath2}
\sum_{e \in E} (\sum_{\forall g \in F:l_g <
l_{f'}}y_{g,e}P(g)(3)+max(P(i \in F)(3)y_{i,e}))y_{f',e} \leq P(f')(4)-P(f')(3)
+ 1, f' \in F
\end{equation}

To add a new real-time flow like this to the network without modifying the paths
of other previous real-time flows, we store a {\em slack} of delay for each
real-time flow. Then whenever we add a new real-time flow and modify the local
bounded delay of other flows we check if the increasing delay amounts of the
flows exceed the slack of the flows and then recompute new slacks for these
flows. The slack of a flow $f$ is computed as:

\begin{equation}
	slack_f=P(f)(4)-P(f)(3) +
1 - \sum_{e \in E} (\sum_{\forall g \in F:l_g <
l_{f}}y_{g,e}P(g)(3)+max(P(i \in F)(3)y_{i,e}))y_{f,e}, \forall f \in F
\end{equation}
What we should minimize: power or future paths?

\section{Specification}
\subsection{Message Structures}
The structure of a PATH message (this is often a flit) to set up a real-time 
flow on the network is:

\begin{table}[h]
\begin{center}
  \begin{tabular}{ | l | l | l | l | l | l | l | l | }
    \hline
	Type & Source ID & Destination ID & Virtual Channel ID & 
	$T_{min}$ & $L_{max}$ & $D_{max}$ & (optional) \\
    \hline
  \end{tabular}
\end{center}
\caption{Setup path message}
\label{table:PathMsg}
\end{table}

The structure of a real-time data packet is:

\begin{table}[h]
\begin{center}
  \begin{tabular}{ | l | l | l | l | l |}
    \hline
	Type & Virtual Channel ID & Time stamp or jitter & Packet Length & Data \\ \hline
	\multicolumn{5}{|c|}{Data flit} \\ \hline
	\multicolumn{5}{|c|}{...} \\ \hline
	\multicolumn{5}{|c|}{Data flit} \\
    \hline
  \end{tabular}
\end{center}
\caption{Data message}
\label{table:DataMsg}
\end{table}

\subsection{Considerations}
\includegraphics[width=11cm]{pics/OtherArcs.png}

From this we can consider the format of a data packet since we have the 
tradeoff between the length of a packet and the bounded delay of the packet. 
If the packet is long, then our network is more efficient, however, the bounded 
delay will probably large.
\subsection{Routing}
When a reservation path packet reaches a node and the calculated routing link 
to another router cannot afford the service time and transmission rate or delay 
bound for that reserving flow. What should the router do:

\begin{table}[h]
\begin{center}
  \begin{tabular}{ | p{3cm} | p{4cm} | p{4cm} |}
    \hline
	Options & Advantage & Disadvantage \\ \hline
	Backtrack to the source node (router) & 
	Possible find another better path in another direction &
	Possibly cannot find a path \\ \hline
	Backtrack to current node (router) and try another link (direction) &
	- Possibly to find another path (maybe longer).  

	- Can always find a path if the path exists using exhaust search	&
	- The overhead for finding another path using exhaust search is potentially  big.

	- The algorithm routing can be complicated and expensive if implemented in hardware. \\
    \hline
  \end{tabular}
\end{center}
\caption{Routing Considerations}
\label{table:RoutingConsiderations}
\end{table}

Furthermore, should we employ routing able mechanism, this means that a table 
is used at each node to store the information like left utilization $\frac{S}{T}$ at 
each link and delay bound at each link from source to destination or we can 
use some dynamic routing protocols like dynamic source routing (DSR) as in wireless networks.

\section{Implementation}
The router architecture can be implemented as in \cite{Rexford98arouter, Zhang_1service} 
and extend \cite{PehDelayModel, PehSpecPipeR} to have better performance.

We use Noxim \cite{Noxim} as the implementation platform. Currently, we have tried
to set up real-time paths and admission control for real-time paths when sharing 
the same link. The real-time packets currently just contain one flit.

\bibliography{RTNoC}
\bibliographystyle{plain}

\end{document}
